{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb0d22d-a821-45b3-89be-c9be73eed678",
   "metadata": {},
   "source": [
    "# Course 3 Week 1 Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dede426-e3c5-4d3f-9b29-ebadfc6e9f86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafe1e70-5250-4372-8d6c-c8c8c065c9ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def radioButton(value, checked=False):\n",
    "    \n",
    "    value = value.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "    \n",
    "    if checked:\n",
    "        radioBtnStr = f\"<input type='radio' id='{value}' value='{value}' checked='checked'>\\n<label for='{value}'>{value}</label><br>\"\n",
    "    else:\n",
    "        radioBtnStr = f\"<input type='radio' id='{value}' value='{value}' >\\n<label for='{value}'>{value}</label><br>\"\n",
    "    \n",
    "    display(Markdown(radioBtnStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4449aa-fd7e-4b4f-b8ad-235a5e0007a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def formatMCQ(query, options, ans):\n",
    "    display(Markdown(query))\n",
    "    for option in options:\n",
    "        if option == ans:\n",
    "            radioButton(option, checked = True)\n",
    "        else:\n",
    "            radioButton(option, checked = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597110f5-1284-4ffe-851e-0616d0fd477b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCQs = {\"What is the name of the object used to tokenize sentences?\": \n",
    "        ([\"CharacterTokenizer\", \"TextTokenizer\", \"WordTokenizer\", \"Tokenizer\"], \"Tokenizer\"),\n",
    "          \"What is the name of the method used to tokenize a list of sentences?\": \n",
    "        ([\"tokenize_on_text(sentences)\", \"fit_on_texts(sentences)\", \"tokenize(sentences)\", \"fit_to_text(sentences)\"], \"fit_on_texts(sentences)\"),\n",
    "          \"Once you have the corpus tokenized, what’s the method used to encode a list of sentences to use those tokens?\":\n",
    "        ([\"text_to_sequences(sentences)\",\"text_to_tokens(sentences)\",\"texts_to_sequences(sentences)\", \"texts_to_tokens(sentences)\"], \"texts_to_sequences(sentences)\"),\n",
    "          \"When initializing the tokenizer, how do you specify a token to use for unknown words?\":\n",
    "        ([\"unknown_word=<Token>\", \"oov_token=<Token>\", \"unknown_token=<Token>\", \"out_of_vocab=<Token>\"], \"oov_token=<Token>\"),     \n",
    "          \"If you don’t use a token for out of vocabulary words, what happens at encoding?\":\n",
    "        ([\"The word is replaced by the most common token\", \"The word isn’t encoded, and the sequencing ends\", \n",
    "          \"The word isn’t encoded, and is replaced by a zero in the sequence\",\"The word isn’t encoded, and is skipped in the sequence\"], \n",
    "         \"The word isn’t encoded, and is skipped in the sequence\"),\n",
    "          \"If you have a number of sequences of different lengths, how do you ensure that they are understood when fed into a neural network?\":\n",
    "        ([\"Process them on the input layer of the Neural Network using the pad_sequences property\",\n",
    "          \"Specify the input layer of the Neural Network to expect different sizes with dynamic_length\",\n",
    "          \"Make sure that they are all the same length using the pad_sequences method of the tokenizer\",\n",
    "          \"Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace\"],\n",
    "        \"Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace\"),\n",
    "          \"If you have a number of sequences of different length, and call pad_sequences on them, what’s the default result?\":\n",
    "        ([\"They’ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones\",\n",
    "          \"They’ll get cropped to the length of the shortest sequence\",\n",
    "          \"Nothing, they’ll remain unchanged\",\n",
    "          \"They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones\"], \n",
    "        \"They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones\"),\n",
    "           \"When padding sequences, if you want the padding to be at the end of the sequence, how do you do it?\":\n",
    "        ([\"Call the padding method of the pad_sequences object, passing it ‘post’\", \n",
    "          \"Pass padding=’post’ to pad_sequences when initializing it\",\n",
    "          \"Pass padding=’after’ to pad_sequences when initializing it\", \n",
    "          \"Call the padding method of the pad_sequences object, passing it ‘after’\"], \n",
    "        \"Pass padding=’post’ to pad_sequences when initializing it\")\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c32e3179-cd71-4e5b-b727-fe6e3d842443",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What is the name of the object used to tokenize sentences?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='CharacterTokenizer' value='CharacterTokenizer' >\n",
       "<label for='CharacterTokenizer'>CharacterTokenizer</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='TextTokenizer' value='TextTokenizer' >\n",
       "<label for='TextTokenizer'>TextTokenizer</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='WordTokenizer' value='WordTokenizer' >\n",
       "<label for='WordTokenizer'>WordTokenizer</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Tokenizer' value='Tokenizer' checked='checked'>\n",
       "<label for='Tokenizer'>Tokenizer</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What is the name of the method used to tokenize a list of sentences?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='tokenize_on_text(sentences)' value='tokenize_on_text(sentences)' >\n",
       "<label for='tokenize_on_text(sentences)'>tokenize_on_text(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='fit_on_texts(sentences)' value='fit_on_texts(sentences)' checked='checked'>\n",
       "<label for='fit_on_texts(sentences)'>fit_on_texts(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='tokenize(sentences)' value='tokenize(sentences)' >\n",
       "<label for='tokenize(sentences)'>tokenize(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='fit_to_text(sentences)' value='fit_to_text(sentences)' >\n",
       "<label for='fit_to_text(sentences)'>fit_to_text(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Once you have the corpus tokenized, what’s the method used to encode a list of sentences to use those tokens?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='text_to_sequences(sentences)' value='text_to_sequences(sentences)' >\n",
       "<label for='text_to_sequences(sentences)'>text_to_sequences(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='text_to_tokens(sentences)' value='text_to_tokens(sentences)' >\n",
       "<label for='text_to_tokens(sentences)'>text_to_tokens(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='texts_to_sequences(sentences)' value='texts_to_sequences(sentences)' checked='checked'>\n",
       "<label for='texts_to_sequences(sentences)'>texts_to_sequences(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='texts_to_tokens(sentences)' value='texts_to_tokens(sentences)' >\n",
       "<label for='texts_to_tokens(sentences)'>texts_to_tokens(sentences)</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "When initializing the tokenizer, how do you specify a token to use for unknown words?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='unknown_word=&lt;Token&gt;' value='unknown_word=&lt;Token&gt;' >\n",
       "<label for='unknown_word=&lt;Token&gt;'>unknown_word=&lt;Token&gt;</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='oov_token=&lt;Token&gt;' value='oov_token=&lt;Token&gt;' checked='checked'>\n",
       "<label for='oov_token=&lt;Token&gt;'>oov_token=&lt;Token&gt;</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='unknown_token=&lt;Token&gt;' value='unknown_token=&lt;Token&gt;' >\n",
       "<label for='unknown_token=&lt;Token&gt;'>unknown_token=&lt;Token&gt;</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='out_of_vocab=&lt;Token&gt;' value='out_of_vocab=&lt;Token&gt;' >\n",
       "<label for='out_of_vocab=&lt;Token&gt;'>out_of_vocab=&lt;Token&gt;</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If you don’t use a token for out of vocabulary words, what happens at encoding?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='The word is replaced by the most common token' value='The word is replaced by the most common token' >\n",
       "<label for='The word is replaced by the most common token'>The word is replaced by the most common token</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='The word isn’t encoded, and the sequencing ends' value='The word isn’t encoded, and the sequencing ends' >\n",
       "<label for='The word isn’t encoded, and the sequencing ends'>The word isn’t encoded, and the sequencing ends</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='The word isn’t encoded, and is replaced by a zero in the sequence' value='The word isn’t encoded, and is replaced by a zero in the sequence' >\n",
       "<label for='The word isn’t encoded, and is replaced by a zero in the sequence'>The word isn’t encoded, and is replaced by a zero in the sequence</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='The word isn’t encoded, and is skipped in the sequence' value='The word isn’t encoded, and is skipped in the sequence' checked='checked'>\n",
       "<label for='The word isn’t encoded, and is skipped in the sequence'>The word isn’t encoded, and is skipped in the sequence</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If you have a number of sequences of different lengths, how do you ensure that they are understood when fed into a neural network?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Process them on the input layer of the Neural Network using the pad_sequences property' value='Process them on the input layer of the Neural Network using the pad_sequences property' >\n",
       "<label for='Process them on the input layer of the Neural Network using the pad_sequences property'>Process them on the input layer of the Neural Network using the pad_sequences property</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Specify the input layer of the Neural Network to expect different sizes with dynamic_length' value='Specify the input layer of the Neural Network to expect different sizes with dynamic_length' >\n",
       "<label for='Specify the input layer of the Neural Network to expect different sizes with dynamic_length'>Specify the input layer of the Neural Network to expect different sizes with dynamic_length</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Make sure that they are all the same length using the pad_sequences method of the tokenizer' value='Make sure that they are all the same length using the pad_sequences method of the tokenizer' >\n",
       "<label for='Make sure that they are all the same length using the pad_sequences method of the tokenizer'>Make sure that they are all the same length using the pad_sequences method of the tokenizer</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace' value='Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace' checked='checked'>\n",
       "<label for='Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace'>Use the pad_sequences function from the tensorflow.keras.preprocessing.sequence namespace</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "If you have a number of sequences of different length, and call pad_sequences on them, what’s the default result?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='They’ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones' value='They’ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones' >\n",
       "<label for='They’ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones'>They’ll get padded to the length of the longest sequence by adding zeros to the end of shorter ones</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='They’ll get cropped to the length of the shortest sequence' value='They’ll get cropped to the length of the shortest sequence' >\n",
       "<label for='They’ll get cropped to the length of the shortest sequence'>They’ll get cropped to the length of the shortest sequence</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Nothing, they’ll remain unchanged' value='Nothing, they’ll remain unchanged' >\n",
       "<label for='Nothing, they’ll remain unchanged'>Nothing, they’ll remain unchanged</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones' value='They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones' checked='checked'>\n",
       "<label for='They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones'>They’ll get padded to the length of the longest sequence by adding zeros to the beginning of shorter ones</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "When padding sequences, if you want the padding to be at the end of the sequence, how do you do it?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Call the padding method of the pad_sequences object, passing it ‘post’' value='Call the padding method of the pad_sequences object, passing it ‘post’' >\n",
       "<label for='Call the padding method of the pad_sequences object, passing it ‘post’'>Call the padding method of the pad_sequences object, passing it ‘post’</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Pass padding=’post’ to pad_sequences when initializing it' value='Pass padding=’post’ to pad_sequences when initializing it' checked='checked'>\n",
       "<label for='Pass padding=’post’ to pad_sequences when initializing it'>Pass padding=’post’ to pad_sequences when initializing it</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Pass padding=’after’ to pad_sequences when initializing it' value='Pass padding=’after’ to pad_sequences when initializing it' >\n",
       "<label for='Pass padding=’after’ to pad_sequences when initializing it'>Pass padding=’after’ to pad_sequences when initializing it</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<input type='radio' id='Call the padding method of the pad_sequences object, passing it ‘after’' value='Call the padding method of the pad_sequences object, passing it ‘after’' >\n",
       "<label for='Call the padding method of the pad_sequences object, passing it ‘after’'>Call the padding method of the pad_sequences object, passing it ‘after’</label><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for query, options in MCQs.items():\n",
    "    formatMCQ(query, options[0], options[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eba615b-3803-4661-bf90-18d13863e7f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
